---
title: "Exploration"
editor: visual
bibliography: references.bib
execute:
  # show code chunk output
  include: true
  # Show the code in the output
  echo: false
  # Show warnings
  warning: true
  # Cache code results
  cache: true
  message: false
format: 
  html:
    toc: true
    code-fold: true
    embed-resources: true
---

```{r}
#| label: DoNotModify
### Utilities for R. 
# Do not modify unless you don't use R: then, delete this chunk.
# Installation of R packages if necessary
install_packages <- function(packages) {
  invisible(
    sapply(
      packages, 
      FUN = function(package) {
        if (!package %in% installed.packages()[, 1]) {
          install.packages(package, repos = "https://cran.rstudio.com/")
        }
      }
    )
  )
}

# Basic packages
install_packages(c("knitR", "formatR", "kableExtra"))

# Chunk font size hook: allows size='small' 
# or any valid Latex font size in chunk options
def.chunk.hook <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(
  chunk = function(x, options) {
    x <- def.chunk.hook(x, options)
    ifelse(
      options$size == "normalsize", 
      yes = x,
      no = paste0("\n \\", options$size, "\n\n", x, "\n\n \\normalsize")
    )
  }
)
```

```{r}
#| label: Options
### Customized R options for this document
# Delete this chunk if you don't use R

# Add necessary packages here
packages <- c("tidyverse", "divent", "vegan", "untb", "sads")
# Install them
install_packages(packages)

# knitr options (https://yihui.org/knitr/options/)
knitr::opts_chunk$set(
  # Code chunk automatic format if tidy is TRUE
  tidy = FALSE, 
  # Tidy code options: remove blank lines and cut lines after 50 characters
  tidy.opts = list(blank = FALSE, width.cutoff = 50),
  # Font size in PDF output
  size = "scriptsize", 
  # Select PDF figures in PDF output if PDF file exists beside PNG file
  knitr.graphics.auto_pdf = TRUE
)
# Text width of R functions output
options(width = 50)

# ggplot style
library("tidyverse")
theme_set(theme_bw())
theme_update(
  panel.background = element_rect(fill = "transparent", colour = NA),
  plot.background = element_rect(fill = "transparent", colour = NA)
)
knitr::opts_chunk$set(dev.args = list(bg = "transparent"))

# Random seed
set.seed(973)
```

## Estimation de $\alpha$

### Ajustement de la RAC

Je propose une méthode alternative d'ajustement : plutôt que maximiser la vraisemblance des données, ajuster la RAC.

```{r}
library("tidyverse")
library("vegan")
data(BCI)
BCI %>% 
  colSums() ->
  BCI_50ha
```


La fonction `lseries_RAC()` calcule le rang théorique de chaque espèces en fonction de son abondance.
Ces rangs ne sont pas entiers.

La fonction `fit_alpha()` estime $\alpha$ en minimisant la distance L1 entre les rangs théoriques (qui dépendent de $\alpha$) et les rangs observés dans la distribution.

```{r}
#| label: fit-alpha
# Theoretical rank of abundances
lseries_RAC <- function(abd, alpha) {
  rank <- vapply(
    abd, 
    function(x) {
      n <- x * log(1 + alpha / sum(abd))
      f <- stats::integrate(function(t) {exp(-t) / t}, lower = n, upper = Inf)
      fv <- f[["value"]]
      return(alpha * fv)
    }, 
    FUN.VALUE = 0
  )
  tibble(rank, abundance = abd) |>
    arrange(rank)
}

# Test
cat("Rang théorique des espèces de BCI\n")
lseries_RAC(BCI_50ha, 50)

# Fit alpha by minimizing the departure of species ranks from their theoretical value in a logseries
fit_alpha <- function(abd) {
  abd_decr <- sort(abd[abd > 0], decreasing = TRUE)
  optimized <- optim(
    par = vegan::fisher.alpha(abd),
    fn = function(alpha) {
      sum(abs(seq_along(abd_decr) - lseries_RAC(abd_decr, alpha)$rank))
    }, 
    method = "L-BFGS-B",
    lower = 0
  )
  optimized$par
}

# Test
# Simulate a logseries with alpha = 50
library("divent")
rcommunity(1, size = 1E6, distribution = "lseries", fisher_alpha = 50) %>% 
  as.numeric() ->
  lseries_abd
# Estimate alpha
cat("Estimation de alpha à partir d'une distribution simulée où alpha = 50")
fit_alpha(lseries_abd)

# BCI
cat("Estimation de alpha à BCI")
(theta <- fit_alpha(BCI_50ha))
# Ajustement sur l'ensemble de la distribution
BCI_50ha %>% 
  as_abundances() %>% 
  autoplot() +
  geom_line(
    data = lseries_RAC(BCI_50ha, alpha = theta),
    aes(x = rank, y = abundance)    
  )
```

La courbe noire est un meilleur ajustement d'une log-série à la distribution de BCI que celui obtenu par maximum de vraisemblance.

## Estimation de $\theta$

$\theta$ est le paramètre de la log-série de la métacommunauté dont la communauté locale est issue.

Il n'y a pas de fonction facile d'accès dans R pour estimer $\theta$:

-   `untb::optimal.theta()` estime $\theta$ en assumant que $m = 1$.

```{r}
#| code-fold: false
library("untb")
optimal.theta(BCI_50ha)
```

-   `untb::optimal.params()` estime $m$ et $\theta$ selon @Etienne2005.
    Les calculs sont extrêmement longs (et échouent avec un message d'erreur) sans utilisation d'un programme externe, pari/GP.
    Le code la fonction `logkda_pari_windows()` est bogué et ne permet pas d'exécuter les calculs.
    Une fonction corrigée est fournie ci-dessous.

-   @Hubbell2001 (page 293) estime la log-série correspondant aux espèces les plus fréquentes de la communauté locale.

### Hubbell (2001)

@Hubbell2001 [page 293] propose de l'estimer en ajustant la courbe rang-abondance aux espèces les plus fréquentes de la communauté en argumentant que ces espèces sont aussi les plus abondantes de la métacommunauté.

```{r}
BCI_50ha %>% 
  sort(decreasing = TRUE) %>% 
  subset(. > median(.)) ->> 
  BCI_dominant
cat("Estimation de alpha pour BCI à partir des espèces abondantes")
(theta <- fit_alpha(BCI_dominant))
# Ajustement
BCI_dominant %>% 
  as_abundances() %>% 
  autoplot() +
  geom_line(
    data = lseries_RAC(BCI_50ha, alpha = theta),
    aes(x = rank, y = abundance)    
  )
```

L'estimation par la méthode de Hubbell est `r round(theta)`.
L'ajustement sur la figure est bon.

### Etienne (2005)

La fonction `logkda_my()` remplace `logkda.pari()` sous Windows.

```{r}
library("untb")
logkda_my <- function(
    a, 
    numerical = TRUE, 
    gp_binary = "gp") {

  command <- paste(gp_binary, "--version", sep = " ")
  if ((system(command, intern = FALSE, ignore.stderr = TRUE)) != 0) {
    stop("pari/gp not installed: try gp_binary='/usr/local/bin/gp' or similar")
  }
  
  pari_string <- "
  logKDAvec(abund) =
   {
     local(S,J,n,m,k,k0,k1,k2,Told,Tnew,specabund,i,j,Sdiff,cnt1,cnt2);
     abund = vecsort(abund);
     S = length(abund);
     J = sum(k = 1,S,abund[k]);
     maxabund = abund[S];
     Sdiff = 1; for(i = 2,S,if(abund[i] != abund[i - 1],Sdiff++));
     specabund = matrix(2,Sdiff,i,j,0); specabund[1,1] = abund[1]; specabund[2,1] = 1;
     cnt1 = 1; cnt2 = 1;
     for(i = 2,S,
         if(abund[i] != abund[i - 1],
            cnt1++;
            cnt2 = 1;
            specabund[1,cnt1] = abund[i];
            specabund[2,cnt1] = cnt2
            ,
            cnt2++;
            specabund[2,cnt1] = cnt2
         )
     );
     
     polyn = vector(1,i,1);
     i = 1;
     if(specabund[1,i] == 1,i++);
     Told = vector(1,i,1);
     for(n = 2,maxabund,
         Tnew = vector(n,m,(n > m) * Told[min(n-1,m)] + Told[max(1,m - 1)] * (m - 1)/(n - 1) + 0. );
         if(n == specabund[1,i],
            for(k0 = 1,specabund[2,i],
                lenpolyn2 = length(polyn) + length(Tnew) - 1;
                polyn = vector(lenpolyn2,k1,sum(k2 = max(1,k1 + 1 - length(Tnew)),min(length(polyn),k1),polyn[k2] * Tnew[k1 + 1 - k2]));
                
            );
            i++;
         );
         Told = vector(n,m,Tnew[m]);
     );
     logKDA = log(polyn);
     
     logKDA
   }
  "
  
#######################
# Fin de logkda.pari() : pas de modification
  
# logkda_pari_windows
#######################

  a <- untb::extant(as.count(a))
  count.string <- paste(as.vector(a), collapse = ",")
  pari_string <- paste(pari_string, "print(logKDAvec([", count.string, "]))")
  cat(pari_string, file = "logkda.gp")
  
# Modifie 797 de https://github.com/RobinHankin/untb/blob/master/R/untb.R
#######################
  logkda.list <- shell(paste(gp_binary, "-q", "logkda.gp"), intern = TRUE)
  # Eliminate the last item of the list that contains a prompt
  if (is.list(logkda.list)) {
    # pari/gp returned a list
    logkda.list <- paste(logkda.list[[-length(logkda.list)]], sep = "", collapse = "")
  } else {
    # pari/gp returned a character vector
    logkda.list <- paste(logkda.list[-length(logkda.list)], sep = "", collapse = "")
  }
########################
# Fin des modifications
  if (numerical) {
    logkda.list <- (as.numeric(unlist(strsplit(gsub("\\[|\\]", "", logkda.list), ","))))
  }
  
  # shell("del logkda.gp")
  return(logkda.list)
}
```


Vérification du fonctionnement de la fonction.

```{r}
#| include: false
# Vérification par les exemples du package untb
zoo <- untb::count(c(pigs = 1, dogs = 1, cats = 2, frogs = 3, bats = 5, slugs = 8))
# Calcul de log(K(D, A)) par R
(l <- logkda.R(zoo, use.brob = TRUE))
# Equivalent par pari/gp
(l_gp <- logkda(zoo, gp_binary = "bin\\gp"))
# Calcul de theta et m
optimal.params(zoo, log.kda = l)  #compare his answer of 7.047958 and 0.22635923.
```

Application à BCI

```{r}
BCI_50ha %>% 
  untb::count() %>% 
  {. ->> BCI_count} %>% 
  # Windows only. gp.exe must be in bin subfolder.
  logkda(gp_binary = "bin\\gp") ->
  BCI_logkda
BCI_count %>% 
  optimal.params(log.kda = BCI_logkda) %>% 
  print() ->
  BCI_params
```

L'estimation selon Etienne est `r round(BCI_params[1])`.

Les valeurs retournées par [Tetame](https://jeromechave.github.io/projects/tetame.htm) sont 47.67 et 0.0934, identiques aux erreurs d'arrondis près.

## Simulation complète

L'objectif est de boucler : à partir des paramètres obtenus avec les données de BCI, simuler une métacommunauté puis une communauté de même taille que BCI.
Si tout va bien, la distribution simulée doit être similaire à la distribution réelle.

Simulation d'une métacommunauté : $J_m = 10^6$ (arbitraire, testé de $10^5$ à $10^7$), $\theta$ obtenu à partir de BCI.

```{r}
J_m <- 1E6
theta <- BCI_params[1]
library("divent")
the_metacommunity <- rcommunity(1, size = J_m , distribution = "lseries", fisher_alpha = theta)
```

Distribution de la communauté locale : $J$ de BCI et $m$ estimé précédemment.

```{r}
J <- sum(BCI)
m <- BCI_params[2]
library("sads")
the_community <- rvolkov(round(Svolkov(theta, m, J)), theta, m, J)
# Number of species in the local community
Svolkov(theta, m, J) %>% 
  round() %>% 
  # Draw the species abundances
  rvolkov(theta, m, J) %>% 
  as_abundances() %>% 
  autoplot() +
  # BCI real distribution
  geom_line(
    data = tibble(abundance = sort(BCI_50ha, decreasing = TRUE)) %>% 
      mutate(rank = seq_len(n())),
    aes(x = rank, y = abundance)
  )
```

La communauté simulée (points rouges) correspond assez bien à la distribution réelle de BCI (ligne noire).

## Paracou 6

Fonctions pour l'ajustement de la RAC en logsérie, copié de `calcul_alpha.qmd`, tests retirés.


Estimation d'alpha à Paracou.

```{r}
library("tidyverse")
library("vegan")
library("divent")
paracou_6_abd %>% 
  metacommunity() %>% 
  {. ->> paracou_6_mc} %>% 
  as.numeric() %>% 
  fit_alpha() %>% 
  print() ->
  paracou_6_alpha
```

Distribution de Paracou

```{r}
# Points d'estimation de la SAC
levels <- c(1:500, 500 + (1:50) * 10, 1000 + (1:50) * 100, 6000 + (1:15) * 1000)
# SAC
paracou_6_mc %>% 
  accum_hill(levels = levels[levels <= abd_sum(., as_numeric = TRUE)]) %>% 
  autoplot() +
  scale_x_log10() +
  # Courbe d'accumulation d'une log-série
  geom_function(fun = \(n) {paracou_6_alpha * log(1 + n / paracou_6_alpha)}, col = "black")
```
